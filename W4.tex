\documentclass{article} 
\usepackage{amsmath}
\usepackage{listings}
\begin{document}
\title{CS231n- Lecture 3}
\maketitle
\section{Optimization}
\ \subsection{Computational Graph}
We need to see computational graph. It's huge in Convolutional Neural Networks and Neural Turing Machine.\\
$f(x,y,z)=(x+y)z$ \\
e.g x=-2, y=5, z=-4\\
$q=x+y$ \\ $\frac{\partial q}{\partial x}=1$ \\ $\frac{\partial q}{\partial y}=1$
$f=qz$ \\ $\frac{\partial f}{\partial q}=z$ \\ $\frac{\partial f}{\partial z} = q$ \\
\\ We made a forward pass, now we'll make a backward one
$\frac{\partial f}{\partial f}=1$ \\
$\frac{\partial f}{\partial z}=x+y=3$ \\ The influence of z on f is three times in positive magnitude \\
$\frac{\partial f}{\partial q}=z=-4$ \\  if q increases by h, then f decreases by 4 times that magnitude
$\frac{\partial f}{\partial y} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial y}=-4 * 1 = -4$ \\
Similarly, $\frac{\partial f}{\partial x} = -4$  \\
Example: $f(w,x)= \frac{1}{1+e^(-(w_0 x_0 + w_1 x_1 + w_2))}$
$f(x) = e^x $
\end{document}
